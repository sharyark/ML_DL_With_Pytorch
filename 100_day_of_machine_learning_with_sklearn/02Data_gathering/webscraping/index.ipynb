{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f774c913-a7ac-4030-96c3-d525b594845e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5ed56ebd-449a-4879-8ee2-137c60d07837",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL to scrape\n",
    "url = \"https://en.wikipedia.org/wiki/Kane_Williamson\"\n",
    "# Headers to mimic a browser\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.88 Safari/537.36\",\n",
    "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "    \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "    \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
    "    \"Connection\": \"keep-alive\",\n",
    "    \"Referer\": \"https://www.google.com/\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2985d34d-7945-41b9-bd4c-18f7f8c11812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send GET request\n",
    "response = rq.get(url, headers=headers)\n",
    "# # Decode response content\n",
    "# if response.encoding is None:\n",
    "#     response.encoding = 'utf-8'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9c909cca-e97d-429f-abe3-32fa2a4e5fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the status code\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "81cd72e6-d940-4425-a217-9c3059b38446",
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = response.text\n",
    "# print(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c00c2296-86b0-465b-9ac2-b718807767be",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(obj,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "543ea5e1-a30c-409f-9552-9d8ac832a080",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(type(soup))\n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba325210-76c2-4878-aff5-25dbe23a27e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contents\n",
      "Early life\n",
      "Domestic career\n",
      "International career\n",
      "International centuries\n",
      "Personal life\n",
      "References\n",
      "External links\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(soup.find_all('h2'))):\n",
    "    print(soup.find_all('h2')[i].text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48aa14eb-70ef-433e-be07-9494ff17d6d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e75de256-b026-49ff-a7b4-da97727e8c1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "# from bs4 import BeautifulSoup\n",
    "\n",
    "# # URL to scrape\n",
    "# url = \"https://en.wikipedia.org/wiki/Kane_Williamson\"\n",
    "\n",
    "# # Headers to mimic a browser\n",
    "# headers = {\n",
    "#     \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.88 Safari/537.36\",\n",
    "#     \"Accept-Language\": \"en-US,en;q=0.9\",\n",
    "#     \"Accept-Encoding\": \"gzip, deflate, br\",\n",
    "#     \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8\",\n",
    "#     \"Connection\": \"keep-alive\",\n",
    "#     \"Referer\": \"https://www.google.com/\",\n",
    "# }\n",
    "\n",
    "# # Send request to the website\n",
    "# response = requests.get(url, headers=headers)\n",
    "\n",
    "# # Handle encoding issue\n",
    "# response.encoding = response.apparent_encoding  # Ensures proper encoding is used\n",
    "\n",
    "# # Parse HTML content using BeautifulSoup\n",
    "# soup = BeautifulSoup(response.text, 'html.parser')  # or 'lxml' if 'html.parser' does not work\n",
    "\n",
    "# # Extract and print the page title or other content\n",
    "# print(soup.title.string)\n",
    "\n",
    "# # Example of extracting a specific section (e.g., infobox data or paragraphs)\n",
    "# for para in soup.find_all('p'):\n",
    "#     print(para.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "73f2ae1b-a25f-456b-8226-0c3a4644592d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page fetched successfully.\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "# URL of the Wikipedia page for Kane Williamson\n",
    "url = \"https://en.wikipedia.org/wiki/Kane_Williamson\"\n",
    "\n",
    "# Headers to mimic a real browser request\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.5993.88 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Send GET request to the page\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    print(\"Page fetched successfully.\")\n",
    "    \n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Extract personal information from the infobox (where bio data is stored)\n",
    "    infobox = soup.find('table', {'class': 'infobox vcard'})\n",
    "    personal_info = {}\n",
    "    \n",
    "    if infobox:\n",
    "        rows = infobox.find_all('tr')\n",
    "        for row in rows:\n",
    "            header = row.find('th')\n",
    "            data = row.find('td')\n",
    "            if header and data:\n",
    "                personal_info[header.text.strip()] = data.text.strip()\n",
    "    else:\n",
    "        print(\"Infobox not found.\")\n",
    "    \n",
    "    # Extracting international team and debut details from the content\n",
    "    international_info = []\n",
    "    infobox_rows = soup.find_all('span', {'class': 'bday'})\n",
    "    for row in infobox_rows:\n",
    "        international_info.append(row.text.strip())\n",
    "    \n",
    "    # Extracting domestic team details from the page\n",
    "    domestic_team_info = []\n",
    "    domestic_teams = soup.find('div', {'class': 'wikitable'})\n",
    "    if domestic_teams:\n",
    "        rows = domestic_teams.find_all('tr')\n",
    "        for row in rows:\n",
    "            cols = row.find_all('td')\n",
    "            if len(cols) > 1:\n",
    "                domestic_team_info.append([col.text.strip() for col in cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a505f7-fa5a-4de6-ad6a-b0becc0c2ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
